{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Intelligence artificielle\" et machine Learning\n",
    "\n",
    "L'idée d'apprentissage automatique (machine learning) est née en 1936 avec le concept de machine universelle d'Alan Turing et de son article de 1950 sur le [test de turing](https://fr.wikipedia.org/wiki/Test_de_Turing). En 1943 deux chercheurs représentent le fonctionnement des neurones avec des circuits électriques, c'est le début de la théorie sur les réseaux neuronaux. En 1952 Arthur Samuel écrit un programme capable de s'améliorer en jouant aux dames. Depuis les progrès ne font que continuer et le machine learning est probablement le secteur de l'informatique le plus en expansion (reconnaissance faciale, conduite automatique, création de vaccins, aide à la prise de décision (data scientist),...).\n",
    "\n",
    "Il existe dans le domaine de l'intelligence artificielle, différentes approches qu'il est intéressant de connaitre:\n",
    "\n",
    "* **Apprentissage supervisé**: on a des exemples que l'on sait classer et qui sont déjà classées. L'ordinateur apprend avec les exemples et leur réponse, puis teste. Par exemple pour distinguer si l'on a une photo de chat ou de chien, l'ordinateur va analyser des centaines de photos dont il a la réponse.\n",
    "* **Apprentissage non supervisé**: l'ordinateur a des exemples mais ne connait pas la réponse.\n",
    "* **Apprentissage par renforcement**: l'algorithme apprend en observant ce qu'il essaye. Un système de récompense/punition lui permet d'améliorer ses choix. L'ordinateur joue au hasard au début et plus il apprend moins il joue au hasard et utilise ce qu'il a trouvé comme 'bonne méthode'. C'est avec ce genre de méthode que l'ordinateur peut apprendre à jouer à differents jeux. Le plus difficile est de choisir ce qui va être une récompense et ce qui sera une sanction. Voici un exemple de cette stratégie appliquée au [poker](https://www.youtube.com/watch?v=nMP2lXxyPZo&list=WL&index=5)\n",
    "* **Apprentissage par transfert**: utiliser des comptétences déjà apprises sur des nouvelles taches qui ont des points communs.\n",
    "\n",
    "## Spécificité des algorithmes d'apprentissage\n",
    "\n",
    "**Un algorithme d'apprentissage NE RESSEMBLE PAS aux algorithmes vus jusqu'à présent.** Il est important de bien comprendre leur particularité.\n",
    "\n",
    "Les algorithmes traditionnels vus jusqu'ici visent à apporter efficacement des **réponses CORRECTES à des problèmes PRECISEMENT définis**. **Les algorithmes à base d'apprentissage** suivent une philosophie différente : apporter une **réponse PLAUSIBLE, mais pas nécessairement exacte, à un problème auquel il est difficile d'appliquer un algorithme traditionnel.** Le problème visé peut typiquement :\n",
    "* Etre d'une complexité telle que le calcul d'une réponse exacte prendrait beaucoup trop de temps (par exemple le meilleur coup à jouer dans une [partie de GO](https://fr.wikipedia.org/wiki/Go_en_informatique). Voir par exemple cette [très bonne vidéo](https://www.youtube.com/watch?v=xuBzQ38DNhE))\n",
    "* Ne pas avoir de définition suffisamment précise (par exemple le choix de la meilleure traduction en français d'un texte écrit en langue étrangère. Voir par exemple [ce site mettant en oeuvre un réseau de neurones](https://www.deepl.com/translator) qui propose des traductions bien meilleures que celle de Google traduction)\n",
    "* Etre basé sur des données incomplètes ou imprécises (par exemple le choix de la meilleure publicité à montrer à un utilisateur d'internet en fonction de ses goûts ou de son humeur du moment. Ce que fait par exemple [cette entreprise française](https://fr.wikipedia.org/wiki/Criteo), côtée au Nasdaq et leader dans le ciblage publicitaire)\n",
    "\n",
    "\n",
    "Dans ce cours, nous allons voir un algorithme d'[apprentissage supervisé](https://fr.wikipedia.org/wiki/Apprentissage_supervis%C3%A9) utilisé en intelligence artificielle : [la méthode des k plus proches voisins](https://fr.wikipedia.org/wiki/M%C3%A9thode_des_k_plus_proches_voisins), en abrégé k-NN ou KNN, de l'anglais k-nearest neighbors\n",
    "\n",
    "# Exemple simpliste d'utilisation de la méthode Knn\n",
    "\n",
    "Afin de travailler sur un exemple, nous allons utiliser un jeu de données relativement connu dans le monde du machine learning : le jeu de données \"iris\". Les Iris sont des fleurs. En botanique, il existe plusieurs espèces du genre iris, notamment les espèces suivantes : Setosa, Virginica et Versicolor\n",
    "\n",
    "| iris setosa | iris virginica  | iris versicolor  |\n",
    "|:-:|:---:|:---:|\n",
    "| ![iris_setosa](https://github.com/seynave/img/raw/master/iris_setosa.jpeg)  | ![iris_virginica](https://github.com/seynave/img/raw/master/iris_virginica.jpeg)  |  ![iris_versicolor](https://github.com/seynave/img/raw/master/iris_versicolor.jpeg) |\n",
    "\n",
    "En 1936, Edgar Anderson a collecté des données afin de quantifier les variations de morphologie des fleurs d'iris de ces trois espèces. Il a notamment mesuré (en cm) la longueur et la largeur des pétales et il a noté l'espèce (\"iris setosa\", \"iris virginica\" ou \"iris versicolor\") pour chaque iris rencontré. Vous trouverez 50 de ces mesures dans le fichier [iris_simplifie.csv](iris_simplifie.csv)\n",
    "\n",
    "En résumé, vous trouverez dans ce fichier :\n",
    "\n",
    "* la longueur des pétales\n",
    "* la largeur des pétales\n",
    "* l'espèce de l'iris (les noms des espèces sont repérées par des chiffres : 0 pour \"iris setosa\", 1 pour \"iris virginica\" et 2 pour \"iris versicolor\")\n",
    "\n",
    "![extrait_du fichier](https://github.com/seynave/img/raw/master/extrait_iris.png)\n",
    "\n",
    "\n",
    "## Problématique\n",
    "\n",
    "> **Etant connu ce jeu de données**, on donne les caractéristiques (largeur et longueur des pétales) d'une **nouvelle fleur d'Iris**. A quelle espèce appartient cette nouvelle fleur ?  \n",
    "Comme indiqué dans le paragraphe précédent, le problème est mal défini  car on ne connaît pas la façon **précise** dont les botanistes classent les fleurs d'iris dans telle ou telle espèce. On ne peut donc pas appliquer une méthode algorithmique traditionnelle.\n",
    "\n",
    "\n",
    "Imaginons qu'au cours d'une promenade vous trouvez un iris. N'étant botaniste, il ne vous est pas vraiment possible de déterminer l'espèce. En revanche, vous êtes capables de mesurer la longueur et la largeur des pétales de cet iris. Partons du principe qu'un pétale fasse 0,5 cm de large et 2 cm de long.\n",
    "\n",
    "Si on se contente de regarder les données du fichier [iris_simplifie.csv](iris_simplifie.csv),  répondre à la question peut paraître difficile. \n",
    "\n",
    "\n",
    "## Résolution graphique sur exemple simpliste\n",
    "\n",
    "Mais grâce à une représentation graphique des données contenues dans le fichier [iris_simplifie.csv](iris_simplifie.csv), le résultat est sans appel : il y a de fortes chances que l'iris trouvé soit de l'espèce \"iris setosa\"\n",
    "\n",
    "|  Représentation graphique du jeu de donnée de Anderson | même graphique... en y ajoutant l'iris trouvé (représenté en noir)   | \n",
    "|:-:|:---:|\n",
    "| ![graphe_iris](https://github.com/seynave/img/raw/master/graphe_iris.png)  | ![graphe_iris](https://github.com/seynave/img/raw/master/graphe_iris_N1.png)  |\n",
    "\n",
    "\n",
    "# Principes de la méthode Knn\n",
    "\n",
    "> Le principe peut être résumé par le diction :  **\"DIS-MOI QUI SONT TES VOISINS, JE TE DIRAI QUI TU ES.\"**\n",
    "\n",
    "Ce que nous avons fait :\n",
    "* nous avons **classé** la nouvelle fleur dans l'espèce *satosa* en fonction des **attributs** longueur et largeur des pétales\n",
    "* Nous avons utilisé un jeu de données déjà classé (établi par un botaniste)\n",
    "* Nous avons vu que la nouvelle fleur était à une **distance plus proche** du groupe vert. Ainsi, par exemple les k=3 \"plus proches voisins\" de la nouvelle fleur sont tous de l'espèce Satosa. (*pour évaluer la distance entre 2 iris, on peut utiliser une règle sur le graphique*)\n",
    "* Nous en avons *naturellement* déduit qu'il est **très probable** que la nouvelle fleur est de l'espèce *satosa*\n",
    "\n",
    "Formalisons tout cela pour établir la méthode Knn :\n",
    "* Permet de résoudre les problèmes de **CLASSIFICATION** d'un élément en fonction d'**ATTRIBUTS**\n",
    "* Pour y arriver la méthode doit préalablement disposer d'un jeu de données déjà classé. C'est donc un **APPRENTISSAGE SUPERVISE**\n",
    "* On choisit de travailler avec **k** voisins (par exemple k = 3). (*On verra plus tard comment choisir la valeur de k*)\n",
    "* La méthode doit disposer d'une méthode de calcul de **DISTANCE** entre le nouvel élément et les autres éléments du jeu de donnée afin de déterminer quels sont les **k VOISINS LES PLUS PROCHES** de ce nouvel élément\n",
    "* On classe le nouvel élément dans la **CLASSE MAJORITAIRE des k plus proches voisins**\n",
    "\n",
    "Je vous conseille de \"jouer\" avec cette [animation sur la méthode des knn](http://hmalherbe.fr/thalesm/gestclasse/documents/Premiere_NSI/Animations/k_plus_proches_voisins/k_plus_proches_voisins.html) appliquée à un cas simple (toujours 2 attributs) afin de bien comprendre la méthode. Ou encore l'animation ci-dessous :\n",
    "\n",
    "![gif](https://github.com/seynave/img/raw/master/algo_1_sur_2.gif)\n",
    "\n",
    "## Un peu de vocabulaire\n",
    "\n",
    "> Quelques termes à retenir car ils seront utilisés lors des exercices, devoirs et QCM\n",
    "\n",
    "Soit une **base de donnée** contenant plusieurs **éléments** (par exemple celle constituée sur les iris par Anderson)\n",
    "\n",
    "| **Termes à connaître**  | **Définition**  | **Exemple (sur les iris)**  |\n",
    "|:-:|:-:|:-:|\n",
    "| **Etiquette** ou **Classe**  | catégories dans lesquelles on souhaite ranger les éléments  | 3 étiquettes : Setosa(vert), Virginica(rouge), Versicolor(bleu)  |\n",
    "| **Attribut** ou **Descripteur**  | Ce qui permet de ranger un élément dans une classe  | 2 descripteurs : Longueur et largeur  |\n",
    "\n",
    "**[Faire Exercices 1 et 2 du TD](TD_algorithme_knn.ipynb)**\n",
    "\n",
    "\n",
    "## Exemple d'applications de la méthode KNN sur des cas plus réalistes\n",
    "\n",
    "Le but ici n'est pas de traiter ces problèmes mais de montrer la **variété** des problèmes de **classifications** auxquels la méthode knn peut répondre.\n",
    "\n",
    "### Jeu de données réel de Anderson\n",
    "\n",
    "> En fait, le jeu de données de Anderson sur les Iris a été volontairement simplifié pour ne garder que 2 attributs, ce qui rend possible la visualisation graphique du problème. Les données originales comprennent en fait 4 attributs :\n",
    "* la largeur des pétales\n",
    "* la longueur des pétales\n",
    "* la largeur des sépales\n",
    "* la longueur des sépales\n",
    "\n",
    "Ouvrez la [vraie base de donnée sur les Iris](iris.csv). Pouvez-vous aussi facilement prédire l'espèce d'une nouvelle fleur d'Iris ? Quel problème rencontrez vous ?\n",
    "\n",
    "### Encore un autre exemple plus général...\n",
    "\n",
    "Luke Skywalker et Han Solo arrivent dans la cantine de la planète Tatooine remplis d'extraterrestres venant de toute la galaxie, tous plus étranges les uns que les autres. Han Solo, qui a beaucoup parcouru la galaxie, a constitué au fil du temps une très longue base de données sur les caractéristiques des extraterrestres et leur caractère belliqueux ou pas.\n",
    "\n",
    "Voici un *court-extrait* de la base de données de Han Solo :\n",
    "\n",
    "| *Couleur* | *Taille en cm* | *Poids* | *Yeux par pair* | *Belliqueux* |\n",
    "|:-----------:|:----------:|:---------:|:-------------------:|:--------------:|\n",
    "| jaune     | 200  | léger   | non               | non          |\n",
    "| bleu     | 150   | moyen   | oui               | oui          |\n",
    "| vert      | 80   | moyen   | oui               | oui          |\n",
    "| jaune     | 60   | moyen   | non               | non          |\n",
    "| rouge     | 170  | lourd   | non               | non          |\n",
    "| vert      | 450   | lourd   | non               | oui          |\n",
    "| vert      | 150  | lourd   | non               | oui          |\n",
    "| jaune     | 20   | léger   | oui               | oui          |\n",
    "\n",
    "Han Solo et Luke s'assoient à une table à côté d'un extraterrestre inconnu vert, de 100cm, plutôt léger avec 5 yeux. Question : Cet extraterrestre est-il belliqueux ? Quels nouveaux problèmes va t-il se poser si vous essayer de répondre à la question en appliquant la méthode knn ?\n",
    "\n",
    "### Constats\n",
    "\n",
    "Dans les exemples plus réalistes, on est confronté à plusieurs problèmes, notamment pour évaluer les distances :\n",
    "* Impossibilité de représenter les Iris de la vraie base de donnée sur un graphique. (Vous savez tracer un graphique à 4 dimensions vous ?) Il n'est donc plus possible de mesurer les distances à la règle.\n",
    "* C'est quoi la distance entre un extraterrestre de couleur jaune et un autre de couleur verte ? C'est quoi la distance entre un extraterrestre lourd et un autre léger ? On a ici des attributs non numériques (mais booléennes ou catégorielles)  \n",
    "\n",
    "### Conclusion\n",
    "\n",
    "1. La notion de **distance** est centrale dans l'algorithme knn (pour déterminer les plus **proches** voisins.) \n",
    "2. Mais il faudra **définir comment calculer une distance** si on a plus de 2 attributs \n",
    "3. Et comment calculer une distance pour **des données non numériques**\n",
    "4. On voit bien l'intérêt de **programmer l'algorithme des knn afin de le faire tourner sur un ordinateur**. Une résolution manuelle, comme dans le tout premier exemple, est illusoire.\n",
    "\n",
    "\n",
    "# Mesure de distances dans l'algorithme knn\n",
    "\n",
    "L'algorithme knn repose de manière critique sur la notion de **distance** entre différents éléments, ceci afin de déterminer les k **plus proches** voisins. \n",
    "\n",
    "## Distances géométriques\n",
    "\n",
    "Il s'agit de la notion naturelle de la distance, celle qui peut être mesurée à la règle. Il existe beaucoup de façon de calculer une distance. Parmi elles, on retiendra les 2 plus couramment utilisées : la distance euclidienne et la distance de Manhattan.\n",
    "\n",
    "| Distance euclidienne et de Manhattan |\n",
    "|:--:|\n",
    "|![distances](https://github.com/seynave/img/raw/master/distance.png)|\n",
    "|*Source : Wikipedia* |\n",
    " \n",
    "\n",
    "### Distance euclidienne\n",
    "\n",
    "La distance euclidienne correspond à la **distance en ligne droite** pour aller d'un point à un autre. C'est la distance naturellement utilisée en mathématiques au lycée (cf notions de vecteurs, théorème de Pythagore...). Sur la figure ci-dessus, la distance verte est une distance euclidienne\n",
    "\n",
    "Formule dans le plan : $distance = \\sqrt{(x_A^2- x_B^2)+(y_A^2- y_B^2)} = \\sqrt{{\\triangle {x}}^2 + {\\triangle{y}}^2}$\n",
    "\n",
    "Cette formule peut être généralisée dans un espace à n-dimensions (utile lorsque l'algorithme knn utilisent n attributs) : $distance = \\sqrt{\\sum (\\triangle{}^2})$\n",
    "\n",
    "\n",
    "### Distance de Manhattan\n",
    "\n",
    "La distance de Manhattan mesure la distance qu'il faudrait parcourir **en se déplaçant le long des arêtes d'un quadrillage**. C'est par exemple la mesure de la distance de marche dans les rues d'une ville quadrillée de \"manière parfaite\" (d'où le nom de *Manhattan*). Sur la figure ci-dessus, les distances rouge, bleue et jaune, toutes égales, sont des distances de Manhattan.\n",
    "\n",
    "Formule dans le plan : $distance = |x_A- x_B|+|y_A- y_B|$\n",
    "\n",
    "Formule généralisée dans un espace à n-dimensions (utile lorsque l'algorithme knn utilisent n attributs) : $distance = \\sum |\\triangle|$\n",
    "\n",
    "Ce qu'il faut bien comprendre c'est que si on calcule une distance entre deux éléments A et B, on n'obtiendra pas nécessairement la même valeur avec la distance euclidienne et la distance de Manhattan. C'est tout à fait normal : on ne mesure pas la même chose.\n",
    "\n",
    "**[Faire Exercices 3 et 4 du TD](TD_algorithme_knn.ipynb)**\n",
    "\n",
    "## Distance entre chaînes de caractères\n",
    "\n",
    "Considérons un algorithme knn travaillant cette fois sur des chaînes de caractères. Comment évaluer la *distance* entre 2 chaînes de caractères ? Là encore, il existe plusieurs méthode de calcul.\n",
    "\n",
    "### Distance de Hamming\n",
    "\n",
    "La distance de Hamming compte le nombre de caractères par lesquels 2 chaînes diffèrent. [Plus d'informations](https://fr.wikipedia.org/wiki/Distance_de_Hamming) et [exemples](https://fr.wikipedia.org/wiki/Distance_de_Hamming#Exemples)\n",
    "\n",
    "### Distance d'édition ou distance de Levenshtein\n",
    "\n",
    "La distance d'édition donne le nombre minimal d'ajouts, de suppressions et de modifications permettant de passer d'une chaîne de caractère à l'autre. [Plus d'informations](https://fr.wikipedia.org/wiki/Distance_de_Levenshtein) et [exemples](http://jeux-et-mathematiques.davalan.org/lang/algo/lev/index.html)\n",
    "\n",
    "### Distance sémantique\n",
    "\n",
    "Cette distance s'appuie sur le sens des mots plutôt que sur la suite de caractères constituants les mots\n",
    "\n",
    "Là encore, utiliser la distance de Hamming, d'édition ou sémantique entre 2 mots donne la plupart du temps des valeurs différentes puisqu'elles ne mesurent pas la même chose.\n",
    "\n",
    "## Distance entre données non numériques\n",
    "\n",
    "* Si l'attribut ne fait pas apparaître de notion d'ordre :\n",
    "    * distance = 0 (pour des attributs de même valeur)\n",
    "    * distance = 1 (pour des attributs de valeur différente)\n",
    "* Si l'attribut fait apparaître une notion d'ordre, on peut affecter des valeurs numériques ordonnées à chaque valeur.\n",
    "\n",
    "En reprenant les exemples précédents, on aura pour les couleurs des extraterrestres (pas de notion d'ordre):\n",
    "\n",
    "* distance (jaune, vert) = 1\n",
    "* distance (jaune, jaune) = 0\n",
    "\n",
    "Et en affectant 3 à lourd, 2 à moyen et 1 à léger (il y a une notion d'ordre) :\n",
    "* distance (lourd, lourd) = 3 - 3 = 0\n",
    "* distance (lourd, léger) = 3 - 1 = 2\n",
    "\n",
    "## Quelle distance choisir ?\n",
    "\n",
    "Il n'y a pas de réponse toute faite à cette question. Tout dépend du contexte dans lequel est appliqué l'algorithme knn.\n",
    "\n",
    "Exemple, si le contexte concerne :\n",
    "* des populations d'oiseaux on choisira sans doute la distance euclidienne. \n",
    "* un jeu de dames ou tout autre jeu qui se déroule sur une grille, on choisira sans doute la distance Manhattan \n",
    "* les fautes de frappes sur un clavier, on choisira sans doute la distance d'édition\n",
    "\n",
    "Parfois le choix de telle ou telle distance va fortement influencer la catégorisation knn, parfois non. En effet, ce n'est pas tant la valeur des distances qui est importante mais la **comparaison** entre différentes distances car on cherche les plus proches voisins.\n",
    "\n",
    "\n",
    "## Normalisation des distances\n",
    "\n",
    "Si on applique les formules de distances \"telle quelles\", on peut donner trop d'importance à un attribut plutôt qu'à un autre dans le calcul de distance et donc dans le fait qu'un élément est \"proche\" d'un autre.\n",
    "\n",
    "Par exemple prenons 3 individus adultes et 2 attributs (taille et âge):\n",
    "\n",
    "|nom|taille(en m)|âge (en année)|\n",
    "|:--:|:--:|:--:|\n",
    "|Alice|1.6|28|\n",
    "|Bob|2.0|26|\n",
    "|Charly|1.65|25|\n",
    "\n",
    "$d_{Alice/Bob} = (2.0-1.6)+(28-26) = 0.4 + 2 = 2.4$  \n",
    "$d_{Alice/Charly} = (1.65-1.6)+(28-25) = 0.05 + 3 = 3.05$\n",
    "\n",
    "Ceci signifie que (sur des critères d'âge et de taille) Alice est plus proche de Bob que de Charly. Mais c'est illogique car Alice a à peu près le même âge que Bob et Charly mais Alice est beaucoup plus petite que Bob tout en étant à peu près de la même taille que Charly !! Le calcul nous dit que Alice est plus proche de Bob que de Charly !(!?!?!?!)\n",
    "\n",
    "Ceci s'explique parce que le calcul de la distance est beaucoup plus influencée par l'âge que par la taille. Et donc le calcul de la distance surpondère l'importance de l'âge sur la distance. Pour le dire autrement, dans le calcul une différence d'âge de 1 an (ce qui est peu) va compter autant qu'une différence de taille de 1m (ce qui est énorme).\n",
    "\n",
    "Pour résoudre ce problème, on peut **normaliser les distances** afin que pour chaque attribut, la distance soit comprise entre 0 et 1. Pour cela, il suffit de **diviser chaque composante par sa plage de variation** ($V_{max} - V_{min}$)\n",
    "\n",
    "Pour des individus adultes, on peut prendre par exemple (souvent on prend les valeurs maximales et minimales rencontrées dans la base de données) :\n",
    "* $age_{min} = 18$\n",
    "* $age_{max} = 120$\n",
    "* $taille_{min} = 1.4$\n",
    "* $taille_{max} = 2.1$\n",
    "\n",
    "Le nouveau calcul normalisé donne : \n",
    "\n",
    "$d_{Alice/Bob} = \\frac{(2.0-1.6)}{(2.1-1.4)}+\\frac{(28-26)}{(120-18)} = 0.571 + 0.019 = 0.59$  \n",
    "\n",
    "$d_{Alice/Charly} = \\frac{(1.65-1.6)}{(2.1-1.4)}+\\frac{(28-25)}{(120-18)} = 0.071 + 0.029 = 0.1$\n",
    "\n",
    "Dans ce cas Alice est plus proche de Charly que de Bob. Ce qui est logique compte tenu des critères d'âge et de taille.\n",
    "\n",
    "**[Faire Exercice 5 du TD](TD_algorithme_knn.ipynb)**\n",
    "\n",
    "# Choix et influence du paramètre k\n",
    "\n",
    "Reprenons un cas simpliste (2 attributs numériques) que l'on peut représenter dans le plan (comme dans le tout premier exemple). En appliquant la méthode knn, le point C1 doit-il être classé parmi les verts ou parmi les bleus ?\n",
    "\n",
    "<img src=\"https://github.com/seynave/img/raw/master/influence_k.png\" style=\"width:60%\"/>\n",
    "\n",
    "* avec k = 3, C1 est classé \"bleu\"\n",
    "* avec k = 5, C1 est classé \"rouge\"\n",
    "\n",
    "On remarque que le choix de k peut changer le résultat (pas toujours heureusement!). Dès lors, comment choisir k ?\n",
    "\n",
    "Là encore, pas de recette miracle. Remarquons néanmoins que :\n",
    "* avec k trop grand, le classement est fortement influencé par des points trop éloignés et donc normalement peu significatifs\n",
    "* avec k trop petit (typiquement k = 1), le classement est uniquement déterminé par son voisin immédiat même si une écrasante majorité de ses autres voisins lui auraient donné un autre classement. On dit que le classement est sensible au *bruit*\n",
    "\n",
    "Plusieurs solutions pour choisir k :\n",
    "* Utiliser en plus du jeu de donnée (celui fournit pour l'apprentissage), un **autre** jeu de données (jeu de test) pour lequel le classement est connu. Tester ensuite l'algorithme knn sur les éléments de ce jeu de test pour différents k et choisir le k qui donne le meilleur taux de réussite.\n",
    "* Si on ne sait pas faire autrement, choisir k = nb d'attributs + 1 \n",
    "\n",
    "\n",
    "# Vigilance et limites \"techniques\" de l'algorithme des knn\n",
    "\n",
    "Si le principe de l'algorithme knn est très simple, son application peut poser de nombreux problèmes. En particulier un bon **data scientist** doit avoir en plus de ses compétences de programmeur, de **connaissances dans le domaine** sur lequel il emploit ses méthodes :\n",
    "* Les attributs choisis doivent être pertinents pour fonder le classement (voir TD où on devine la couleur des cheveux d'un enfant en fonction de sa position dans la cour de récréation). Pour cela des connaissances disciplinaires ou \"métiers\" sont nécessaires. **Sans connaissance disciplinaire, un \"data scientist\" peut être vite amené à faire du \"grand n'importe quoi\" tout en appliquant correctement ses algorithmes**\n",
    "* Certains attributs doivent-ils être plus pondérés que d'autres ?\n",
    "\n",
    "Mais il doit aussi avoir des **compétences en mathématiques et notamment en statistiques** :\n",
    "* la base de données peut être soumises à certains **biais** qui vont fausser le résultat et que seuls des compétences en statistique peuvent débusquer.\n",
    "* Les données sont-elles suffisamment bien réparties entre les différences classes (pour ne pas donner trop d'importance à certaines classes plutôt que d'autre)\n",
    "* Les données sont-elles suffisamment nombreuses ?\n",
    "\n",
    "Bref, pour faire un travail de qualité de **data scientist**, il faut des connaissances en informatique **ET** des connaissances en math et en stat **ET** des connaissances dans le domaine de l'étude (voir figure ci-dessous). Je vous conseille cette [autre très bonne vidéo](https://www.youtube.com/watch?v=vs_Zzf_vL2I) pour vous en convaincre...\n",
    "\n",
    "Ainsi si par exemple vous avez des connaissances uniquement en statistique et en info, vous pouvez faire autant de machine learning à condition de ne surtout pas appliquer tout ça à de la biologie, sociologie, économie etc...  \n",
    "Et si vous avez des connaissances uniquement en biologie et en info, vous pouvez développer autant de logiciels sur la biologie que vous voulez à condition de ne surtout pas commencer à fabriquer vos propres bases de données...\n",
    "\n",
    "![data science](https://github.com/seynave/img/raw/master/dataScience.png)\n",
    "\n",
    "# ~~Sciences~~ Algorithmes sans conscience n'est que ruine de l'âme (Rabelais)\n",
    "\n",
    "Comme les sciences, les algorithmes, et notamment ceux de l'intelligence artificielle, peuvent être capables du meilleur comme du pire en fonction des usages. Ainsi la méthode knn peut être utilisé :\n",
    "* pour identifier (classer) une tumeur cancéreuse d'une tumeur bénigne. Ce grain de beauté est-il un mélanome ?\n",
    "* pour faire du ciblage publicitaire et pousser les utilisateurs à l'acte d'achat, augmentant ainsi la surconsommation aux conséquences sociales et écologiques toujours plus fortes et inquiétantes.\n",
    "\n",
    "Ensuite le nerf de la guerre dans les algorithmes de machine learning est la qualité et la quantité des données (on parle de \"big data\"). Il faut noter l'importance des stratégies mises en place par les GAFAM (Google, Apple, Facebook, Amazon et Microsoft) afin de récupérer un grand nombre de données concernant leurs clients. Ces données sont très souvent utilisées pour \"nourrir\" des algorithmes de machine learning (comment, d'après vous, Amazon arrive à proposer à ces clients des \"suggestions d'achats\" souvent très pertinentes ?). Les services \"gratuits\" qu'elles apportent à leurs utilisateurs sont en fait le moyen de récupérer toujours plus de données toujours plus intimes qu'elles revendent ensuite à d'autres organisations. Il ne faut surtout pas croire que c'est un petit phénomène. Il n'y a qu'à voir le chiffre d'affaire de Facebook, chiffre d'affaire uniquement généré par la revente d'informations sur ses utilisateurs. Au final circulent des données de plus en plus précises et nombreuses sur les individus, données qui ne doivent/devraient (n'auraient pas dû ???) pas tomber entre certaines mains...\n",
    "\n",
    "Enfin les algorithmes IA sont de plus en plus utilisées dans l'information (rédaction d\"articles\" de presse...) et prennent de plus en plus de place dans les décisions publiques. Là se posent des questions majeures en terme de liberté et de démocratie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:pink;\">\n",
    "<strong>A RETENIR </strong> <br/>\n",
    "    La méthode des <strong>k plus proches voisins</strong> consiste à <strong>deviner le classement</strong> d'un objet connaissant le classement d'objets <strong>similaires</strong> déjà connus et issus <strong>d'une base de donnée</strong>.<br/>\n",
    "    La méthode doit pouvoir disposer d'<strong>une fonction évaluant la distance entre objets</strong> permettant ainsi de déterminer quels sont les k objets <strong>les plus proches de l'objet</strong> qu'on cherche à classer.<br/>\n",
    "    Le classement retenu sera le classement <strong>majoritaire</strong> de ces k objets voisins.<br/>\n",
    "    Le classement obtenu ne sera pas nécessairement exact mais sera d'autant plus plausible que la base de données disponibles sera de donne qualité"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
